{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "================================================================================\n",
    "SCRIPT UNIFICADO DE TREINAMENTO DE MODELOS PREDITIVOS\n",
    "================================================================================\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Este script centraliza o processo de treinamento, avaliação e salvamento de\n",
    "múltiplos modelos de Machine Learning para prever indicadores socioeconômicos\n",
    "e de saúde com base em dados históricos.\n",
    "\n",
    "Modelos Treinados:\n",
    "------------------\n",
    "1. PIB per Capita (R$)\n",
    "2. VAB Agropecuária (R$ 1.000)\n",
    "3. Total de Benefícios Básicos (Bolsa Família)\n",
    "4. Internações por Doenças Respiratórias\n",
    "\n",
    "Metodologia:\n",
    "------------\n",
    "1.  **Carregamento de Dados:** Carrega os datasets necessários.\n",
    "2.  **Engenharia de Features:** Cria variáveis de lag (defasagem) e de taxa de\n",
    "    crescimento para capturar tendências temporais. Esta é a etapa mais\n",
    "    importante para transformar dados de série temporal em um formato que\n",
    "    modelos de regressão como o LightGBM possam aprender.\n",
    "3.  **Divisão Temporal:** Os dados são divididos em conjuntos de treino e teste\n",
    "    com base no ano. Isso simula um cenário real onde prevemos o futuro\n",
    "    (ex: ano de 2022) usando apenas informações do passado (até 2021).\n",
    "    Uma divisão aleatória seria incorreta aqui, pois levaria a \"vazamento de dados\"\n",
    "    do futuro para o treino.\n",
    "4.  **Treinamento do Modelo:** Utiliza o LightGBM, um algoritmo de Gradient Boosting\n",
    "    eficiente e de alta performance, ideal para dados tabulares.\n",
    "5.  **Avaliação:** Mede o desempenho dos modelos usando RMSE (Erro Quadrático Médio\n",
    "    da Raiz) e R² (Coeficiente de Determinação).\n",
    "6.  **Análise de Importância (SHAP):** Gera gráficos SHAP para entender quais\n",
    "    features são mais influentes nas previsões de cada modelo.\n",
    "7.  **Salvamento:** Salva os modelos treinados e a lista de colunas utilizadas,\n",
    "    prontos para serem carregados pelo dashboard Streamlit.\n",
    "\n",
    "Autor: Seu Nome\n",
    "Data: DD/MM/AAAA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO E CONSTANTES ---\n",
    "# Centralizar as configurações facilita a manutenção do código.\n",
    "\n",
    "# Caminhos para os arquivos de dados\n",
    "DATA_DIR = '../data/RESULTADOS/'\n",
    "MODELS_DIR = '../models/'\n",
    "\n",
    "# Garante que o diretório de modelos exista\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Definição das features que serão usadas para criar lags e taxas de crescimento.\n",
    "# Estas são as variáveis preditoras principais que capturam a dinâmica temporal.\n",
    "FEATURES_PARA_LAG_BASE = [\n",
    "    'Desmatamento (km²)', 'PIB per capita (R$)', 'VAB Agropecuária (R$ 1.000)',\n",
    "    'Focos de Queimada', 'Área plantada soja (ha)', 'Total Rebanho (Bovino)'\n",
    "]\n",
    "\n",
    "# Features adicionais para os modelos específicos que também precisam de lag\n",
    "FEATURES_PARA_LAG_BENEFICIOS = FEATURES_PARA_LAG_BASE + ['Total de Benefícios Básicos (Bolsa Família)']\n",
    "FEATURES_PARA_LAG_RESPIRATORIO = FEATURES_PARA_LAG_BASE + ['Total de Benefícios Básicos (Bolsa Família)', 'Internações por Doenças Respiratórias']\n",
    "\n",
    "# Parâmetros do LightGBM. Foram otimizados para um bom equilíbrio entre performance e tempo de treino.\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression_l1',  # Otimiza para o Erro Absoluto Médio (MAE), mais robusto a outliers\n",
    "    'metric': 'rmse',              # Métrica de avaliação durante o treino\n",
    "    'n_estimators': 1500,          # Número máximo de árvores de decisão\n",
    "    'learning_rate': 0.03,         # Taxa de aprendizado (passo do gradiente)\n",
    "    'feature_fraction': 0.8,       # Porcentagem de features a ser usada em cada árvore\n",
    "    'bagging_fraction': 0.8,       # Porcentagem de dados a ser usada em cada iteração (reduz overfitting)\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0.1,              # Regularização L1\n",
    "    'lambda_l2': 0.1,              # Regularização L2\n",
    "    'verbose': -1,                 # Suprime mensagens durante o treino\n",
    "    'n_jobs': -1,                  # Usa todos os cores de CPU disponíveis\n",
    "    'seed': 42                     # Garante a reprodutibilidade dos resultados\n",
    "}\n",
    "\n",
    "# --- 2. FUNÇÕES AUXILIARES ---\n",
    "\n",
    "def carregar_dados(caminho_arquivo):\n",
    "    \"\"\"Carrega e prepara o dataframe inicial.\"\"\"\n",
    "    print(f\"Carregando dados de '{caminho_arquivo}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(caminho_arquivo)\n",
    "        # Ordenar por município e ano é CRUCIAL para que os cálculos de lag/shift funcionem corretamente.\n",
    "        df = df.sort_values(by=['Município', 'Ano']).reset_index(drop=True)\n",
    "        print(\"Dados carregados com sucesso.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: Arquivo '{caminho_arquivo}' não encontrado. Abortando.\")\n",
    "        return None\n",
    "\n",
    "def criar_features_temporais(df, features_para_lag):\n",
    "    \"\"\"\n",
    "    Cria features de lag (ano anterior) e de crescimento (variação percentual).\n",
    "    Esta função é o coração da engenharia de features para séries temporais.\n",
    "    \"\"\"\n",
    "    print(\"Iniciando engenharia de features (lags e crescimento)...\")\n",
    "    df_featured = df.copy()\n",
    "    for feature in features_para_lag:\n",
    "        if feature in df_featured.columns:\n",
    "            # Lag de 1 ano: Traz o valor do ano anterior para a linha atual.\n",
    "            # O groupby('Município') garante que o lag não \"vaze\" de um município para outro.\n",
    "            df_featured[f'{feature}_lag1'] = df_featured.groupby('Município')[feature].shift(1)\n",
    "            \n",
    "            # Taxa de crescimento: Calcula a variação percentual em relação ao ano anterior.\n",
    "            # Isso captura a \"aceleração\" ou \"desaceleração\" da variável.\n",
    "            df_featured[f'{feature}_growth'] = df_featured.groupby('Município')[feature].pct_change()\n",
    "        else:\n",
    "            print(f\"Aviso: A coluna '{feature}' não foi encontrada para criar lag.\")\n",
    "            \n",
    "    # Após calcular 'pct_change', podem surgir valores infinitos (divisão por zero).\n",
    "    # Substituímos por 0 para evitar problemas no modelo.\n",
    "    df_featured.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    print(\"Engenharia de features concluída.\")\n",
    "    return df_featured\n",
    "\n",
    "def treinar_avaliar_e_salvar_modelo(df_completo, nome_alvo, features_usadas, nome_modelo_amigavel, caminho_modelo, caminho_colunas):\n",
    "    \"\"\"\n",
    "    Função genérica para executar o ciclo completo de treinamento de um modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"INICIANDO TREINAMENTO PARA O MODELO: {nome_modelo_amigavel.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- 3.1. Preparação dos Dados Específicos do Modelo ---\n",
    "    print(f\"Definindo a variável alvo: '{nome_alvo}' do ano seguinte.\")\n",
    "    # O alvo (y) é o valor da variável no ano seguinte (t+1).\n",
    "    # Usamos os dados do ano atual (t) para prever o ano seguinte.\n",
    "    df_modelo = df_completo.copy()\n",
    "    df_modelo['target'] = df_modelo.groupby('Município')[nome_alvo].shift(-1)\n",
    "\n",
    "    # Removemos linhas com valores NaN. Elas são geradas pelo `shift` do lag e do alvo.\n",
    "    # Essas linhas não podem ser usadas para treinar ou testar o modelo.\n",
    "    df_modelo.dropna(subset=['target'] + [f for f in df_modelo.columns if '_lag1' in f or '_growth' in f], inplace=True)\n",
    "    \n",
    "    y = df_modelo['target']\n",
    "    # 'Município' e o próprio alvo original são removidos das features (X).\n",
    "    X = df_modelo.drop(columns=['target', 'Município', nome_alvo])\n",
    "    # Mantemos o 'Ano' por enquanto para fazer a divisão temporal.\n",
    "    \n",
    "    print(f\"Total de amostras válidas para o modelo: {len(X)}\")\n",
    "\n",
    "    # --- 3.2. Divisão Temporal (Treino/Teste) ---\n",
    "    print(\"Realizando divisão temporal: treino até 2021, teste em 2022...\")\n",
    "    ano_corte = 2021\n",
    "    \n",
    "    X_train = X[X['Ano'] <= ano_corte]\n",
    "    y_train = y[X['Ano'] <= ano_corte]\n",
    "    X_test = X[X['Ano'] > ano_corte]\n",
    "    y_test = y[X['Ano'] > ano_corte]\n",
    "\n",
    "    # Agora que a divisão foi feita, o 'Ano' já cumpriu sua função e pode ser removido das features.\n",
    "    X_train = X_train.drop(columns=['Ano'])\n",
    "    X_test = X_test.drop(columns=['Ano'])\n",
    "    \n",
    "    # Garantir que as colunas de treino e teste estejam na mesma ordem\n",
    "    model_columns = X_train.columns.tolist()\n",
    "    X_test = X_test[model_columns]\n",
    "\n",
    "    print(f\"Tamanho do conjunto de treino: {len(X_train)} amostras.\")\n",
    "    print(f\"Tamanho do conjunto de teste: {len(X_test)} amostras.\")\n",
    "\n",
    "    # --- 3.3. Treinamento do Modelo LightGBM ---\n",
    "    print(\"Treinando o modelo LightGBM...\")\n",
    "    model = lgb.LGBMRegressor(**LGB_PARAMS)\n",
    "    \n",
    "    # O `early_stopping` monitora a performance no set de validação (X_test, y_test)\n",
    "    # e para o treino se a performance não melhorar por 100 rodadas, evitando overfitting.\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_test, y_test)],\n",
    "              eval_metric='rmse',\n",
    "              callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "    # --- 3.4. Avaliação de Performance ---\n",
    "    print(\"Avaliando o modelo no conjunto de teste...\")\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"\\n--- RESULTADOS DE PERFORMANCE ---\")\n",
    "    print(f\"  - RMSE (Erro Quadrático Médio da Raiz): {rmse:,.2f}\")\n",
    "    print(f\"  - R² (Coeficiente de Determinação):     {r2:.3f}\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # --- 3.5. Salvamento do Modelo e Colunas ---\n",
    "    print(\"Salvando o modelo e a lista de colunas...\")\n",
    "    joblib.dump(model, caminho_modelo)\n",
    "    joblib.dump(model_columns, caminho_colunas)\n",
    "    print(f\"  - Modelo salvo em: '{caminho_modelo}'\")\n",
    "    print(f\"  - Colunas salvas em: '{caminho_colunas}'\")\n",
    "\n",
    "    # --- 3.6. Análise de Importância com SHAP ---\n",
    "    print(\"Gerando análise de importância das features com SHAP...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # Gráfico de Barras: Importância média de cada feature\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "    plt.title(f'Importância Média das Features - {nome_modelo_amigavel}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Gráfico Beeswarm: Impacto do valor de cada feature na previsão\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.title(f'Impacto Detalhado das Features - {nome_modelo_amigavel}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"TREINAMENTO PARA '{nome_modelo_amigavel.upper()}' CONCLUÍDO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac556544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de 'data/RESULTADOS/df_final2.csv'...\n",
      "ERRO: Arquivo 'data/RESULTADOS/df_final2.csv' não encontrado. Abortando.\n",
      "Iniciando engenharia de features (lags e crescimento)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m     exit()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df_featured = \u001b[43mcriar_features_temporais\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFEATURES_PARA_LAG_RESPIRATORIO\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# --- Treinar Modelo 1: PIB per Capita ---\u001b[39;00m\n\u001b[32m     15\u001b[39m treinar_avaliar_e_salvar_modelo(\n\u001b[32m     16\u001b[39m     df_completo=df_featured,\n\u001b[32m     17\u001b[39m     nome_alvo=\u001b[33m'\u001b[39m\u001b[33mPIB per capita (R$)\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     caminho_colunas=os.path.join(MODELS_DIR, \u001b[33m'\u001b[39m\u001b[33mmodel_columns.joblib\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mcriar_features_temporais\u001b[39m\u001b[34m(df, features_para_lag)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03mCria features de lag (ano anterior) e de crescimento (variação percentual).\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03mEsta função é o coração da engenharia de features para séries temporais.\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIniciando engenharia de features (lags e crescimento)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m df_featured = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m()\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features_para_lag:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m df_featured.columns:\n\u001b[32m    115\u001b[39m         \u001b[38;5;66;03m# Lag de 1 ano: Traz o valor do ano anterior para a linha atual.\u001b[39;00m\n\u001b[32m    116\u001b[39m         \u001b[38;5;66;03m# O groupby('Município') garante que o lag não \"vaze\" de um município para outro.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'copy'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- 4. BLOCO DE EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Carregar os dois datasets principais\n",
    "    df_path = os.path.join(DATA_DIR, 'df_final2.csv')\n",
    "    \n",
    "    df = carregar_dados(df_path)\n",
    "\n",
    "    if df is None or df is None:\n",
    "        exit()\n",
    "\n",
    "    df_featured = criar_features_temporais(df, FEATURES_PARA_LAG_RESPIRATORIO)\n",
    "\n",
    "    # --- Treinar Modelo 1: PIB per Capita ---\n",
    "    treinar_avaliar_e_salvar_modelo(\n",
    "        df_completo=df_featured,\n",
    "        nome_alvo='PIB per capita (R$)',\n",
    "        features_usadas=FEATURES_PARA_LAG_BASE,\n",
    "        nome_modelo_amigavel='PIB per Capita',\n",
    "        caminho_modelo=os.path.join(MODELS_DIR, 'modelo_pib_pred.joblib'),\n",
    "        caminho_colunas=os.path.join(MODELS_DIR, 'model_columns.joblib')\n",
    "    )\n",
    "\n",
    "    # --- Treinar Modelo 2: VAB Agropecuária ---\n",
    "    treinar_avaliar_e_salvar_modelo(\n",
    "        df_completo=df_featured,\n",
    "        nome_alvo='VAB Agropecuária (R$ 1.000)',\n",
    "        features_usadas=FEATURES_PARA_LAG_BASE,\n",
    "        nome_modelo_amigavel='VAB Agropecuária',\n",
    "        caminho_modelo=os.path.join(MODELS_DIR, 'modelo_vab_pred.joblib'),\n",
    "        caminho_colunas=os.path.join(MODELS_DIR, 'vab_model_columns.joblib')\n",
    "    )\n",
    "    \n",
    "    # --- Treinar Modelo 3: Benefícios Sociais ---\n",
    "    treinar_avaliar_e_salvar_modelo(\n",
    "        df_completo=df_featured,\n",
    "        nome_alvo='Total de Benefícios Básicos (Bolsa Família)',\n",
    "        features_usadas=FEATURES_PARA_LAG_BENEFICIOS,\n",
    "        nome_modelo_amigavel='Benefícios Sociais',\n",
    "        caminho_modelo=os.path.join(MODELS_DIR, 'modelo_beneficios_pred.joblib'),\n",
    "        caminho_colunas=os.path.join(MODELS_DIR, 'beneficios_model_columns.joblib')\n",
    "    )\n",
    "\n",
    "    # --- Treinar Modelo 4: Saúde Respiratória ---\n",
    "    treinar_avaliar_e_salvar_modelo(\n",
    "        df_completo=df_featured,\n",
    "        nome_alvo='Internações por Doenças Respiratórias',\n",
    "        features_usadas=FEATURES_PARA_LAG_RESPIRATORIO,\n",
    "        nome_modelo_amigavel='Saúde Respiratória',\n",
    "        caminho_modelo=os.path.join(MODELS_DIR, 'modelo_respiratorio_pred.joblib'),\n",
    "        caminho_colunas=os.path.join(MODELS_DIR, 'respiratorio_model_columns.joblib')\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"#\"*80)\n",
    "    print(\"TODOS OS MODELOS FORAM TREINADOS E SALVOS COM SUCESSO!\")\n",
    "    print(f\"Os arquivos estão prontos no diretório: '{MODELS_DIR}'\")\n",
    "    print(\"#\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
